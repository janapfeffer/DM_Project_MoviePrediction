{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after import: 43872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>History</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>...</th>\n",
       "      <th>John Carradine</th>\n",
       "      <th>Lionel Barrymore</th>\n",
       "      <th>Charles Lane</th>\n",
       "      <th>John Wayne</th>\n",
       "      <th>Henry Fonda</th>\n",
       "      <th>Michael Caine</th>\n",
       "      <th>Boris Karloff</th>\n",
       "      <th>James Franco</th>\n",
       "      <th>Grey Griffin</th>\n",
       "      <th>Rating_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000000</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000000</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>101.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16000000</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>127.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>106.0</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget     id    imdb_id original_language  runtime  vote_count  Mystery  \\\n",
       "0  30000000    862  tt0114709                en     81.0        5415      0.0   \n",
       "1  65000000   8844  tt0113497                en    104.0        2413      0.0   \n",
       "2         0  15602  tt0113228                en    101.0          92      0.0   \n",
       "3  16000000  31357  tt0114885                en    127.0          34      0.0   \n",
       "4         0  11862  tt0113041                en    106.0         173      0.0   \n",
       "\n",
       "   Foreign  History  TV Movie  ...  John Carradine  Lionel Barrymore  \\\n",
       "0      0.0      0.0       0.0  ...               0                 0   \n",
       "1      0.0      0.0       0.0  ...               0                 0   \n",
       "2      0.0      0.0       0.0  ...               0                 0   \n",
       "3      0.0      0.0       0.0  ...               0                 0   \n",
       "4      0.0      0.0       0.0  ...               0                 0   \n",
       "\n",
       "   Charles Lane  John Wayne  Henry Fonda  Michael Caine  Boris Karloff  \\\n",
       "0             0           0            0              0              0   \n",
       "1             0           0            0              0              0   \n",
       "2             0           0            0              0              0   \n",
       "3             0           0            0              0              0   \n",
       "4             0           0            0              0              0   \n",
       "\n",
       "   James Franco  Grey Griffin  Rating_Label  \n",
       "0             0             0             4  \n",
       "1             0             0             3  \n",
       "2             0             0             3  \n",
       "3             0             0             3  \n",
       "4             0             0             3  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "df_movies = pd.read_csv(\"classificationPreprocessing.csv\")\n",
    "print(\"Length after import: \" + str(len(df_movies)))\n",
    "df_movies = df_movies.fillna(0)\n",
    "df_movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we loaded all the libaries and data that we need, we can start with the classification tasks.\n",
    "\n",
    "Since we have a lot of features it makes sense to eliminate features that do not have a significant impact on the prediction to improve our perfromance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-62b1eb6e0901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n\u001b[0;32m      9\u001b[0m               scoring='accuracy')\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrfecv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimal number of features : %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrfecv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# drop columns that are not needed maybe implement feature selction...\n",
    "\n",
    "\n",
    "# features_to_remove = ['id', 'imdb_id','vote_count','+18','id','actors','spokenLanguages','productionCountries','productionCompanies','original_language','hasHomepage','part_of_collection''orig_lv', 'orig_el', 'orig_fa', 'orig_tl', 'orig_ta', 'orig_th',\n",
    "#        'orig_mn', 'orig_zh', 'orig_te', 'orig_kk', 'orig_zu', 'orig_et',\n",
    "#        'orig_mr', 'orig_eu', 'orig_sv', 'orig_no', 'orig_pl', 'orig_cs',\n",
    "#        'orig_cy', 'orig_bs', 'orig_de', 'orig_lo', 'orig_xx', 'orig_ko',\n",
    "#        'orig_hu', 'orig_sr', 'orig_da', 'orig_pt', 'orig_nl', 'orig_en',\n",
    "#        'orig_it', 'orig_tr', 'orig_hr', 'orig_cn', 'orig_ka', 'orig_ar',\n",
    "#        'orig_ja', 'orig_0', 'orig_hi', 'orig_ro', 'orig_af', 'orig_sk',\n",
    "#        'orig_fr', 'orig_fi', 'orig_he', 'orig_uk', 'orig_bg', 'orig_ml',\n",
    "#        'orig_es', 'orig_bn', 'orig_ab', 'orig_wo', 'orig_ca', 'orig_ru',\n",
    "#        'orig_id', 'orig_is', 'orig_lv', '18+',\n",
    "#        'John Carradine', 'Lionel Barrymore', 'Charles Lane', 'John Wayne',\n",
    "#        'Henry Fonda', 'Michael Caine', 'Boris Karloff', 'James Franco',\n",
    "#        'Grey Griffin','James Stewart', 'Bess Flowers', 'John George', 'Mickey Rooney',\n",
    "#        'Ward Bond', 'Irving Bacon', 'James Mason', 'Ray Milland','Harry Carey', 'Robert Mitchum', 'Stellan Skarsgård', 'Peter Stormare',\n",
    "#        'Christopher Lee', 'Keenan Wynn', 'Burt Reynolds', 'Vincent Price',\n",
    "#        'Donald Pleasence','Tom Hanks',\n",
    "#        'Wallace Shawn', 'Robin Williams', 'Robert De Niro', 'Danny Trejo',\n",
    "#        ' Jr.', 'Paul Giamatti', 'Martin Sheen', 'Frank Welker',\n",
    "#        'Anthony Hopkins', 'Ed Harris', 'Bruce Willis', 'Woody Harrelson',\n",
    "#        'Gene Hackman', 'Lance Henriksen', 'Nicolas Cage', 'Ron Perlman',\n",
    "#        'Christopher Plummer', 'Susan Sarandon', 'James Earl Jones',\n",
    "#        'Jim Broadbent', 'Keith David', 'Richard Jenkins', 'Morgan Freeman',\n",
    "#        'Malcolm McDowell', 'Michael Ironside', 'William H. Macy',\n",
    "#        'Harvey Keitel', 'Christian Slater', 'Alec Baldwin',\n",
    "#        'Christopher Lloyd', 'Steve Buscemi', 'Christopher Walken',\n",
    "#        'Jeff Bridges', 'Michael Gambon', 'John Cusack', 'James Caan',\n",
    "#        'Brian Cox', 'Jackie Chan', 'Liam Neeson', 'John Goodman',\n",
    "#        'Harry Dean Stanton', 'Bruce Dern', 'Unnamed: 83', 'John Hurt',\n",
    "#        'Dan Aykroyd', 'John Turturro', 'Samuel L. Jackson', 'M. Emmet Walsh',\n",
    "#        'Udo Kier', 'Max von Sydow', 'Stanley Tucci', 'Whoopi Goldberg',\n",
    "#        'Robert Duvall', 'Forest Whitaker', 'Ben Kingsley', 'John Leguizamo',\n",
    "#        'Anthony Quinn', 'Dennis Hopper', 'Donald Sutherland', 'Ned Beatty',\n",
    "#        'Helen Mirren', 'Eric Roberts', 'Dick Miller', 'Willem Dafoe',\n",
    "#        'Danny Glover', 'Gérard Depardieu', 'J.K. Simmons', 'Rutger Hauer',\n",
    "#        'Donald Pleasence',\n",
    "#        'Bette Davis']\n",
    "# for i in features_to_remove:\n",
    "#     if i in df_movies.columns:\n",
    "#         df_movies = df_movies.drop(columns=i)\n",
    "# print(df_movies.head(5))\n",
    "# df_movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have exactly the data we want we start with the spitting.\n",
    "\n",
    "1. First of all we separate the features from our targte(the rating).\n",
    "2. We split our data into training and test data in order to evaluate our model later. The proportions will be 60% to 40%\n",
    "3. We creaze a kfold cross validation that we will later use for our models in order to evaluate them better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target variable\n",
    "rating = df_movies['Rating_Label'] # weight\n",
    "features = df_movies.drop(columns=['Rating_Label'])\n",
    "\n",
    "# encode labels\n",
    "lab_enc = LabelEncoder()\n",
    "rating = lab_enc.fit_transform(rating)\n",
    "features[\"director\"] = features[\"director\"].astype(str)\n",
    "features[\"director\"] = lab_enc.fit_transform(features[\"director\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate RFECV visualizer with a linear SVM classifier\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = LinearSVC()\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=stratified_10_fold_cv,\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(features, rating)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(features, rating, test_size=0.4, random_state=42, stratify=rating )\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial evaluation of different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forest:\n",
      "Accuracy: 0.511311185822554\n",
      "Precision: 0.4719965270681225\n",
      "Recall: 0.511311185822554\n",
      "f1_score: 0.4791512657864734\n",
      "\n",
      "Scores knn:\n",
      "Accuracy: 0.45894352954584305\n",
      "Precision: 0.41191148810887285\n",
      "Recall: 0.45894352954584305\n",
      "f1_score: 0.42366141160021964\n",
      "\n",
      "Scores Decision Tree:\n",
      "Accuracy: 0.43780272380192603\n",
      "Precision: 0.4401846737696026\n",
      "Recall: 0.43780272380192603\n",
      "f1_score: 0.43893008194608707\n",
      "\n",
      "Scores Naive Bayes:\n",
      "Accuracy: 0.47820388626132543\n",
      "Precision: 0.3822040809097275\n",
      "Recall: 0.47820388626132543\n",
      "f1_score: 0.3635542266173593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores SVC:\n",
      "Accuracy: 0.5146732007521796\n",
      "Precision: 0.5513608998649818\n",
      "Recall: 0.5146732007521796\n",
      "f1_score: 0.37087514802024674\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forest:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_rf)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a KNN\n",
    "knn_reg = KNeighborsClassifier()\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_knn)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a DecisionTreeClassifier\n",
    "dt_reg = DecisionTreeClassifier()\n",
    "dt_reg.fit(features_train, rating_train)\n",
    "rating_pred_dt = dt_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Decision Tree:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_dt)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_dt)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a GaussianNB\n",
    "nb_reg = GaussianNB()\n",
    "nb_reg.fit(features_train, rating_train)\n",
    "rating_pred_nb = nb_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Naive Bayes:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_nb)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_nb)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a SVC\n",
    "svc_reg = LinearSVC()\n",
    "svc_reg.fit(features_train, rating_train)\n",
    "rating_pred_svc = svc_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores SVC:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_svc)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_svc)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print()\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n",
    "\n",
    "# metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It seems that KNN & Random Forrest are the best classifiers. With those two we will now do some parameter tuning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see with wich k the algorithm works best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "best score is 0.524636249667591 with params {'n_neighbors': 29}\n"
     ]
    }
   ],
   "source": [
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier()\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "\n",
    "\n",
    "# #compute accuracy score\n",
    "\n",
    "# accuracy_knn = cross_val_score(knn_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "# for i, acc in enumerate(accuracy_knn):\n",
    "#     print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "# print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "# # print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "# # print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# # print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# # print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "\n",
    "#Tuning of algorithm\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': range(2, 30)\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(knn_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "Fold 0: Accuracy = 51.04364326375711%\n",
      "Fold 1: Accuracy = 53.15110098709187%\n",
      "Fold 2: Accuracy = 52.80941533788914%\n",
      "Fold 3: Accuracy = 52.088078967350036%\n",
      "Fold 4: Accuracy = 52.297759210026584%\n",
      "Fold 5: Accuracy = 52.27963525835866%\n",
      "Fold 6: Accuracy = 51.957430634739644%\n",
      "Fold 7: Accuracy = 52.851711026615966%\n",
      "Fold 8: Accuracy = 52.69961977186311%\n",
      "Fold 9: Accuracy = 53.46007604562738%\n",
      "Average Accuracy = 52.46384705033196%\n"
     ]
    }
   ],
   "source": [
    "# do now Knn with k = 26 and applie 10 cross fold\n",
    "\n",
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier(n_neighbors=29)\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(knn_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "# print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning of Random forrest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.5544960680773469 with params {'criterion': 'entropy', 'max_depth': 10, 'max_features': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "# print(\"Scores knn:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_rf)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "# #compute accuracy score\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "# print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "# print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "# print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "#Tuning of algorithm\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'max_depth':[3,5,10,None],\n",
    "     'criterion':[\"gini\", \"entropy\"],\n",
    "     'max_features':[\"auto\",\"log2\",None]\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(rf_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forrest:\n",
      "Fold 0: Accuracy = 56.20493358633776%\n",
      "Fold 1: Accuracy = 56.71981776765376%\n",
      "Fold 2: Accuracy = 55.84662110858011%\n",
      "Fold 3: Accuracy = 54.21412300683372%\n",
      "Fold 4: Accuracy = 55.943790353209266%\n",
      "Fold 5: Accuracy = 54.29331306990881%\n",
      "Fold 6: Accuracy = 54.77004941087039%\n",
      "Fold 7: Accuracy = 55.32319391634981%\n",
      "Fold 8: Accuracy = 54.52471482889734%\n",
      "Fold 9: Accuracy = 55.2851711026616%\n",
      "Average Accuracy = 55.312572815130245%\n"
     ]
    }
   ],
   "source": [
    "# do now Random Forest with entropy, maxdeepth 3 and applie 10 cross fold\n",
    "\n",
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier(criterion='entropy', max_depth=10, max_features=None)\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forrest:\")\n",
    "\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(rf_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "# print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "# print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
