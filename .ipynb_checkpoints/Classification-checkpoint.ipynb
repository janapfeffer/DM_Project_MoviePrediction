{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from xgboost import XGBRegressor\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after import: 43872\n",
      "     budget     id  runtime  Documentary  Foreign  Action  Horror  War  \\\n",
      "0  30000000    862     81.0          0.0      0.0     0.0     0.0  0.0   \n",
      "1  65000000   8844    104.0          0.0      0.0     0.0     0.0  0.0   \n",
      "2         0  15602    101.0          0.0      0.0     0.0     0.0  0.0   \n",
      "3  16000000  31357    127.0          0.0      0.0     0.0     0.0  0.0   \n",
      "4         0  11862    106.0          0.0      0.0     0.0     0.0  0.0   \n",
      "\n",
      "   Romance  Adventure  ...  actor_Donald Sutherland  actor_Robert De Niro  \\\n",
      "0      0.0        0.0  ...                        0                     0   \n",
      "1      0.0        1.0  ...                        0                     0   \n",
      "2      1.0        0.0  ...                        0                     0   \n",
      "3      1.0        0.0  ...                        0                     0   \n",
      "4      0.0        0.0  ...                        0                     0   \n",
      "\n",
      "   actor_Samuel L. Jackson  actor_Jackie Chan  actor_Michael Caine  \\\n",
      "0                        0                  0                    0   \n",
      "1                        0                  0                    0   \n",
      "2                        0                  0                    0   \n",
      "3                        0                  0                    0   \n",
      "4                        0                  0                    0   \n",
      "\n",
      "   actor_Christopher Lee  actor_Frank Welker  actor_John Carradine  \\\n",
      "0                      0                   0                     0   \n",
      "1                      0                   0                     0   \n",
      "2                      0                   0                     0   \n",
      "3                      0                   0                     0   \n",
      "4                      0                   0                     0   \n",
      "\n",
      "   actor_Gérard Depardieu  Rating_Label  \n",
      "0                       0             4  \n",
      "1                       0             3  \n",
      "2                       0             3  \n",
      "3                       0             3  \n",
      "4                       0             3  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'id', 'runtime', 'Documentary', 'Foreign', 'Action', 'Horror',\n",
       "       'War', 'Romance', 'Adventure', 'Thriller', 'History', 'Drama', 'Family',\n",
       "       'Comedy', 'TV Movie', 'Crime', 'Western', 'Mystery', 'Fantasy',\n",
       "       'Animation', 'Music', 'Science Fiction', 'part_of_collection', '+18',\n",
       "       'hasHomepage', '18+', 'spokenLanguages', 'movieId', 'imdbId',\n",
       "       'director', 'actors', 'pcomp_Orion Pictures', 'pcomp_New Line Cinema',\n",
       "       'pcomp_Gaumont', 'pcomp_Twentieth Century Fox Film Corporation',\n",
       "       'pcomp_Walt Disney Productions', 'pcomp_Paramount Pictures',\n",
       "       'pcomp_Universal Pictures', 'pcomp_Village Roadshow Pictures',\n",
       "       'pcomp_StudioCanal', 'pcomp_Columbia Pictures Corporation',\n",
       "       'pcomp_Regency Enterprises', 'pcomp_Touchstone Pictures',\n",
       "       'pcomp_Mosfilm', 'pcomp_RKO Radio Pictures', 'pcomp_Miramax Films',\n",
       "       'pcomp_TriStar Pictures', 'pcomp_Columbia Pictures',\n",
       "       'pcomp_Toho Company', 'pcomp_Relativity Media',\n",
       "       'pcomp_Walt Disney Pictures', 'pcomp_BBC Films', 'pcomp_United Artists',\n",
       "       'actor_Bess Flowers', 'actor_John Wayne', 'actor_Donald Sutherland',\n",
       "       'actor_Robert De Niro', 'actor_Samuel L. Jackson', 'actor_Jackie Chan',\n",
       "       'actor_Michael Caine', 'actor_Christopher Lee', 'actor_Frank Welker',\n",
       "       'actor_John Carradine', 'actor_Gérard Depardieu', 'Rating_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "df_movies = pd.read_csv(\"classificationPreprocessingGeneral.csv\")\n",
    "print(\"Length after import: \" + str(len(df_movies)))\n",
    "df_movies = df_movies.fillna(0)\n",
    "print(df_movies.head(5))\n",
    "df_movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we loaded all the libaries and data that we need, we can start with the classification tasks.\n",
    "\n",
    "Since we have a lot of features it makes sense to eliminate features that do not have a significant impact on the prediction to improve our perfromance. Also we have to drop the columns that are anyways not needed like to actor column, which got one hot encoded already in preprocessing or the ids of the movie..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     budget  runtime  Documentary  Foreign  Action  Horror  War  Romance  \\\n",
      "0  30000000     81.0          0.0      0.0     0.0     0.0  0.0      0.0   \n",
      "1  65000000    104.0          0.0      0.0     0.0     0.0  0.0      0.0   \n",
      "2         0    101.0          0.0      0.0     0.0     0.0  0.0      1.0   \n",
      "3  16000000    127.0          0.0      0.0     0.0     0.0  0.0      1.0   \n",
      "4         0    106.0          0.0      0.0     0.0     0.0  0.0      0.0   \n",
      "\n",
      "   Adventure  Thriller  ...  actor_Donald Sutherland  actor_Robert De Niro  \\\n",
      "0        0.0       0.0  ...                        0                     0   \n",
      "1        1.0       0.0  ...                        0                     0   \n",
      "2        0.0       0.0  ...                        0                     0   \n",
      "3        0.0       0.0  ...                        0                     0   \n",
      "4        0.0       0.0  ...                        0                     0   \n",
      "\n",
      "   actor_Samuel L. Jackson  actor_Jackie Chan  actor_Michael Caine  \\\n",
      "0                        0                  0                    0   \n",
      "1                        0                  0                    0   \n",
      "2                        0                  0                    0   \n",
      "3                        0                  0                    0   \n",
      "4                        0                  0                    0   \n",
      "\n",
      "   actor_Christopher Lee  actor_Frank Welker  actor_John Carradine  \\\n",
      "0                      0                   0                     0   \n",
      "1                      0                   0                     0   \n",
      "2                      0                   0                     0   \n",
      "3                      0                   0                     0   \n",
      "4                      0                   0                     0   \n",
      "\n",
      "   actor_Gérard Depardieu  Rating_Label  \n",
      "0                       0             4  \n",
      "1                       0             3  \n",
      "2                       0             3  \n",
      "3                       0             3  \n",
      "4                       0             3  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'runtime', 'Documentary', 'Foreign', 'Action', 'Horror',\n",
       "       'War', 'Romance', 'Adventure', 'Thriller', 'History', 'Drama', 'Family',\n",
       "       'Comedy', 'TV Movie', 'Crime', 'Western', 'Mystery', 'Fantasy',\n",
       "       'Animation', 'Music', 'Science Fiction', 'part_of_collection',\n",
       "       'hasHomepage', '18+', 'director', 'pcomp_Orion Pictures',\n",
       "       'pcomp_New Line Cinema', 'pcomp_Gaumont',\n",
       "       'pcomp_Twentieth Century Fox Film Corporation',\n",
       "       'pcomp_Walt Disney Productions', 'pcomp_Paramount Pictures',\n",
       "       'pcomp_Universal Pictures', 'pcomp_Village Roadshow Pictures',\n",
       "       'pcomp_StudioCanal', 'pcomp_Columbia Pictures Corporation',\n",
       "       'pcomp_Regency Enterprises', 'pcomp_Touchstone Pictures',\n",
       "       'pcomp_Mosfilm', 'pcomp_RKO Radio Pictures', 'pcomp_Miramax Films',\n",
       "       'pcomp_TriStar Pictures', 'pcomp_Columbia Pictures',\n",
       "       'pcomp_Toho Company', 'pcomp_Relativity Media',\n",
       "       'pcomp_Walt Disney Pictures', 'pcomp_BBC Films', 'pcomp_United Artists',\n",
       "       'actor_Bess Flowers', 'actor_John Wayne', 'actor_Donald Sutherland',\n",
       "       'actor_Robert De Niro', 'actor_Samuel L. Jackson', 'actor_Jackie Chan',\n",
       "       'actor_Michael Caine', 'actor_Christopher Lee', 'actor_Frank Welker',\n",
       "       'actor_John Carradine', 'actor_Gérard Depardieu', 'Rating_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that are not needed maybe implement feature selction...\n",
    "\n",
    "\n",
    "\n",
    "features_to_remove = ['actors', 'movieId', 'imdbId', 'id', '+18','spokenLanguages'\n",
    "                     ]\n",
    "for i in features_to_remove:\n",
    "    if i in df_movies.columns:\n",
    "        df_movies = df_movies.drop(columns=i)\n",
    "print(df_movies.head(5))\n",
    "df_movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have exactly the data we want we start with the spitting.\n",
    "\n",
    "1. First of all we separate the features from our targte(the rating).\n",
    "2. We split our data into training and test data in order to evaluate our model later. The proportions will be 60% to 40%\n",
    "3. We create a kfold cross validation that we will later use for our models in order to evaluate them better\n",
    "4. We encode data that needs to be encoded -> ratings and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 26323 Features and 26323 Ratings\n",
      "Test: 17549 Features and 17549 Ratings\n"
     ]
    }
   ],
   "source": [
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# separate features and target variable\n",
    "rating = df_movies['Rating_Label'] # weight\n",
    "features = df_movies.drop(columns=['Rating_Label'])\n",
    "\n",
    "# encode labels\n",
    "lab_enc = LabelEncoder()\n",
    "rating = lab_enc.fit_transform(rating)\n",
    "features[\"director\"] = features[\"director\"].astype(str)\n",
    "features[\"director\"] = lab_enc.fit_transform(features[\"director\"])\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(features, rating, test_size=0.4, random_state=42, stratify=rating )\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial evaluation of different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forest:\n",
      "Accuracy: 0.45757593025243604\n",
      "Precision: 0.4249071669646724\n",
      "Recall: 0.45757593025243604\n",
      "f1_score: 0.43665658841356303\n",
      "\n",
      "Scores knn:\n",
      "Accuracy: 0.4457803863468004\n",
      "Precision: 0.38925695496372326\n",
      "Recall: 0.4457803863468004\n",
      "f1_score: 0.4052913082091328\n",
      "\n",
      "Scores Decision Tree:\n",
      "Accuracy: 0.40982392159097386\n",
      "Precision: 0.41564729616972307\n",
      "Recall: 0.40982392159097386\n",
      "f1_score: 0.412654803634187\n",
      "\n",
      "Scores Naive Bayes:\n",
      "Accuracy: 0.5286341102057097\n",
      "Precision: 0.27945402247298246\n",
      "Recall: 0.5286341102057097\n",
      "f1_score: 0.36562578396916195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores SVC:\n",
      "Accuracy: 0.4450965867000969\n",
      "Precision: 0.4119594594528054\n",
      "Recall: 0.4450965867000969\n",
      "f1_score: 0.3730537206521399\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forest:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_rf)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a KNN\n",
    "knn_reg = KNeighborsClassifier()\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_knn)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a DecisionTreeClassifier\n",
    "dt_reg = DecisionTreeClassifier()\n",
    "dt_reg.fit(features_train, rating_train)\n",
    "rating_pred_dt = dt_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Decision Tree:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_dt)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_dt)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a GaussianNB\n",
    "nb_reg = GaussianNB()\n",
    "nb_reg.fit(features_train, rating_train)\n",
    "rating_pred_nb = nb_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Naive Bayes:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_nb)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_nb)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a SVC\n",
    "svc_reg = LinearSVC()\n",
    "svc_reg.fit(features_train, rating_train)\n",
    "rating_pred_svc = svc_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores SVC:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_svc)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_svc)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print()\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n",
    "\n",
    "# metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It seems that KNN & Random Forrest are the best classifiers. With those two we will now do some parameter tuning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see with wich k the algorithm works best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "best score is 0.5151768415454165 with params {'n_neighbors': 29}\n"
     ]
    }
   ],
   "source": [
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier()\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': range(2, 30)\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(knn_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "Fold 0: Accuracy = 51.04364326375711%\n",
      "Fold 1: Accuracy = 51.93621867881549%\n",
      "Fold 2: Accuracy = 52.3538344722855%\n",
      "Fold 3: Accuracy = 51.290812452543655%\n",
      "Fold 4: Accuracy = 51.46221040638056%\n",
      "Fold 5: Accuracy = 51.51975683890577%\n",
      "Fold 6: Accuracy = 51.5773470163436%\n",
      "Fold 7: Accuracy = 52.28136882129277%\n",
      "Fold 8: Accuracy = 51.33079847908745%\n",
      "Fold 9: Accuracy = 50.38022813688213%\n",
      "Average Accuracy = 51.517621856629404%\n",
      "\n",
      "Accuracy on Test Data: 0.5160408000455866\n",
      "f1_score on Test Data: 0.3942884289004468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# do now Knn with k = 29 and applie 10 cross fold\n",
    "\n",
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier(n_neighbors=29)\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(knn_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "print()\n",
    "print(\"Accuracy on Test Data: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"f1_score on Test Data: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning of Random forrest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.5419595030961517 with params {'criterion': 'entropy', 'max_depth': 3, 'max_features': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "#Tuning of algorithm\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'max_depth':[3,5,10,None],\n",
    "     'criterion':[\"gini\", \"entropy\"],\n",
    "     'max_features':[\"auto\",\"log2\",None]\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(rf_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forrest:\n",
      "Fold 0: Accuracy = 54.307400379506646%\n",
      "Fold 1: Accuracy = 54.51784358390282%\n",
      "Fold 2: Accuracy = 54.32801822323462%\n",
      "Fold 3: Accuracy = 53.568716780561886%\n",
      "Fold 4: Accuracy = 54.99430307633878%\n",
      "Fold 5: Accuracy = 54.21732522796353%\n",
      "Fold 6: Accuracy = 54.00988217407829%\n",
      "Fold 7: Accuracy = 54.030418250950575%\n",
      "Fold 8: Accuracy = 53.68821292775665%\n",
      "Fold 9: Accuracy = 54.29657794676807%\n",
      "Average Accuracy = 54.19586985710618%\n",
      "\n",
      "Accuracy on Test Data: 0.5343324405949057\n",
      "f1_score on Test Data: 0.4244380412662057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# do now Random Forest with entropy, maxdeepth 3 and applie 10 cross fold\n",
    "\n",
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier(criterion='entropy', max_depth=3, max_features=None)\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forrest:\")\n",
    "\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(rf_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "print()\n",
    "print(\"Accuracy on Test Data: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"f1_score on Test Data: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Modell with Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after import: 118856\n",
      "   usercluster  movieId    budget   id  runtime  Documentary  Foreign  Action  \\\n",
      "0            0        1  30000000  862     81.0          0.0      0.0     0.0   \n",
      "1            1        1  30000000  862     81.0          0.0      0.0     0.0   \n",
      "2            2        1  30000000  862     81.0          0.0      0.0     0.0   \n",
      "3            3        1  30000000  862     81.0          0.0      0.0     0.0   \n",
      "4            4        1  30000000  862     81.0          0.0      0.0     0.0   \n",
      "\n",
      "   Horror  War  ...  actor_Donald Sutherland  actor_Robert De Niro  \\\n",
      "0     0.0  0.0  ...                        0                     0   \n",
      "1     0.0  0.0  ...                        0                     0   \n",
      "2     0.0  0.0  ...                        0                     0   \n",
      "3     0.0  0.0  ...                        0                     0   \n",
      "4     0.0  0.0  ...                        0                     0   \n",
      "\n",
      "   actor_Samuel L. Jackson  actor_Jackie Chan  actor_Michael Caine  \\\n",
      "0                        0                  0                    0   \n",
      "1                        0                  0                    0   \n",
      "2                        0                  0                    0   \n",
      "3                        0                  0                    0   \n",
      "4                        0                  0                    0   \n",
      "\n",
      "   actor_Christopher Lee  actor_Frank Welker  actor_John Carradine  \\\n",
      "0                      0                   0                     0   \n",
      "1                      0                   0                     0   \n",
      "2                      0                   0                     0   \n",
      "3                      0                   0                     0   \n",
      "4                      0                   0                     0   \n",
      "\n",
      "   actor_Gérard Depardieu  Rating_Label  \n",
      "0                       0             4  \n",
      "1                       0             4  \n",
      "2                       0             4  \n",
      "3                       0             4  \n",
      "4                       0             4  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['usercluster', 'movieId', 'budget', 'id', 'runtime', 'Documentary',\n",
       "       'Foreign', 'Action', 'Horror', 'War', 'Romance', 'Adventure',\n",
       "       'Thriller', 'History', 'Drama', 'Family', 'Comedy', 'TV Movie', 'Crime',\n",
       "       'Western', 'Mystery', 'Fantasy', 'Animation', 'Music',\n",
       "       'Science Fiction', 'part_of_collection', '+18', 'hasHomepage', '18+',\n",
       "       'spokenLanguages', 'imdbId', 'rating_y', 'director', 'actors',\n",
       "       'pcomp_Orion Pictures', 'pcomp_New Line Cinema', 'pcomp_Gaumont',\n",
       "       'pcomp_Twentieth Century Fox Film Corporation',\n",
       "       'pcomp_Walt Disney Productions', 'pcomp_Paramount Pictures',\n",
       "       'pcomp_Universal Pictures', 'pcomp_Village Roadshow Pictures',\n",
       "       'pcomp_StudioCanal', 'pcomp_Columbia Pictures Corporation',\n",
       "       'pcomp_Regency Enterprises', 'pcomp_Touchstone Pictures',\n",
       "       'pcomp_Mosfilm', 'pcomp_RKO Radio Pictures', 'pcomp_Miramax Films',\n",
       "       'pcomp_TriStar Pictures', 'pcomp_Columbia Pictures',\n",
       "       'pcomp_Toho Company', 'pcomp_Relativity Media',\n",
       "       'pcomp_Walt Disney Pictures', 'pcomp_BBC Films', 'pcomp_United Artists',\n",
       "       'actor_Bess Flowers', 'actor_John Wayne', 'actor_Donald Sutherland',\n",
       "       'actor_Robert De Niro', 'actor_Samuel L. Jackson', 'actor_Jackie Chan',\n",
       "       'actor_Michael Caine', 'actor_Christopher Lee', 'actor_Frank Welker',\n",
       "       'actor_John Carradine', 'actor_Gérard Depardieu', 'Rating_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "df_movies_cluster = pd.read_csv(\"classificationPreprocessingWithClustering.csv\")\n",
    "print(\"Length after import: \" + str(len(df_movies)))\n",
    "df_movies_cluster = df_movies.fillna(0)\n",
    "print(df_movies_cluster.head(5))\n",
    "df_movies_cluster.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data set is similair, we just have and additional column usercluster. In order to have comparable results we remove the same columns as in the previous set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118856\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['usercluster', 'budget', 'runtime', 'Documentary', 'Foreign', 'Action',\n",
       "       'Horror', 'War', 'Romance', 'Adventure', 'Thriller', 'History', 'Drama',\n",
       "       'Family', 'Comedy', 'TV Movie', 'Crime', 'Western', 'Mystery',\n",
       "       'Fantasy', 'Animation', 'Music', 'Science Fiction',\n",
       "       'part_of_collection', 'hasHomepage', '18+', 'director',\n",
       "       'pcomp_Orion Pictures', 'pcomp_New Line Cinema', 'pcomp_Gaumont',\n",
       "       'pcomp_Twentieth Century Fox Film Corporation',\n",
       "       'pcomp_Walt Disney Productions', 'pcomp_Paramount Pictures',\n",
       "       'pcomp_Universal Pictures', 'pcomp_Village Roadshow Pictures',\n",
       "       'pcomp_StudioCanal', 'pcomp_Columbia Pictures Corporation',\n",
       "       'pcomp_Regency Enterprises', 'pcomp_Touchstone Pictures',\n",
       "       'pcomp_Mosfilm', 'pcomp_RKO Radio Pictures', 'pcomp_Miramax Films',\n",
       "       'pcomp_TriStar Pictures', 'pcomp_Columbia Pictures',\n",
       "       'pcomp_Toho Company', 'pcomp_Relativity Media',\n",
       "       'pcomp_Walt Disney Pictures', 'pcomp_BBC Films', 'pcomp_United Artists',\n",
       "       'actor_Bess Flowers', 'actor_John Wayne', 'actor_Donald Sutherland',\n",
       "       'actor_Robert De Niro', 'actor_Samuel L. Jackson', 'actor_Jackie Chan',\n",
       "       'actor_Michael Caine', 'actor_Christopher Lee', 'actor_Frank Welker',\n",
       "       'actor_John Carradine', 'actor_Gérard Depardieu', 'Rating_Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that are not needed maybe implement feature selction...\n",
    "\n",
    "\n",
    "\n",
    "features_to_remove = ['actors', 'movieId', 'imdbId', 'id', '+18','spokenLanguages', 'rating_y'\n",
    "                     ]\n",
    "for i in features_to_remove:\n",
    "    if i in df_movies_cluster.columns:\n",
    "        df_movies_cluster = df_movies_cluster.drop(columns=i)\n",
    "print(len(df_movies_cluster))\n",
    "print(df_movies_cluster.usercluster.unique())\n",
    "df_movies_cluster.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create again a startified training and test data, as well as we split the target from the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 71313 Features and 71313 Ratings\n",
      "Test: 47543 Features and 47543 Ratings\n"
     ]
    }
   ],
   "source": [
    "# separate features and target variable\n",
    "rating = df_movies_cluster['Rating_Label'] # weight\n",
    "features = df_movies_cluster.drop(columns=['Rating_Label'])\n",
    "\n",
    "# encode labels\n",
    "lab_enc = LabelEncoder()\n",
    "rating = lab_enc.fit_transform(rating)\n",
    "features[\"director\"] = features[\"director\"].astype(str)\n",
    "features[\"director\"] = lab_enc.fit_transform(features[\"director\"])\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(features, rating, test_size=0.4, random_state=42, stratify=rating )\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the initial evaluation on all the classifiers again, to see wether there is a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forest:\n",
      "Accuracy: 0.5017983720000841\n",
      "Precision: 0.47692403833992775\n",
      "Recall: 0.5017983720000841\n",
      "f1_score: 0.48638186202436773\n",
      "\n",
      "Scores knn:\n",
      "Accuracy: 0.5066571314389079\n",
      "Precision: 0.47381641832633997\n",
      "Recall: 0.5066571314389079\n",
      "f1_score: 0.4844383817235384\n",
      "\n",
      "Scores Decision Tree:\n",
      "Accuracy: 0.45769093241907327\n",
      "Precision: 0.4571399999459843\n",
      "Recall: 0.45769093241907327\n",
      "f1_score: 0.4573674890970003\n",
      "\n",
      "Scores Naive Bayes:\n",
      "Accuracy: 0.4168647329785668\n",
      "Precision: 0.3305878416102089\n",
      "Recall: 0.4168647329785668\n",
      "f1_score: 0.2694179699884696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores SVC:\n",
      "Accuracy: 0.28679300843446986\n",
      "Precision: 0.36002582039721504\n",
      "Recall: 0.28679300843446986\n",
      "f1_score: 0.2821108136581546\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forest:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_rf)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a KNN\n",
    "knn_reg = KNeighborsClassifier()\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_knn)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a DecisionTreeClassifier\n",
    "dt_reg = DecisionTreeClassifier()\n",
    "dt_reg.fit(features_train, rating_train)\n",
    "rating_pred_dt = dt_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Decision Tree:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_dt)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_dt)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a GaussianNB\n",
    "nb_reg = GaussianNB()\n",
    "nb_reg.fit(features_train, rating_train)\n",
    "rating_pred_nb = nb_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Naive Bayes:\")\n",
    "# #compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_nb)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_nb)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print()\n",
    "\n",
    "##### create and fit a SVC\n",
    "svc_reg = LinearSVC()\n",
    "svc_reg.fit(features_train, rating_train)\n",
    "rating_pred_svc = svc_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores SVC:\")\n",
    "#compute the confusion matrix\n",
    "# cnf_matrix = confusion_matrix(rating_test, rating_pred_svc)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_svc)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print()\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n",
    "\n",
    "# metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First evaluation:\n",
    "We can see that the following algortihms got an improvement of accuracy:\n",
    "- Random forrest\n",
    "- KNN\n",
    "- Decision Tree\n",
    "\n",
    "The following are now worse:\n",
    "- Naive Bayes\n",
    "- SVC\n",
    "\n",
    "We will analyze now KNN and random Forrest again to see if we can tune the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n"
     ]
    }
   ],
   "source": [
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier()\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'n_neighbors': range(2, 30)\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(knn_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn optimized:\n",
      "Fold 0: Accuracy = 46.033081020465374%\n",
      "Fold 1: Accuracy = 45.07989907485282%\n",
      "Fold 2: Accuracy = 45.422683302958085%\n",
      "Fold 3: Accuracy = 45.63297350343474%\n",
      "Fold 4: Accuracy = 45.42905215928211%\n",
      "Fold 5: Accuracy = 45.37166900420757%\n",
      "Fold 6: Accuracy = 45.39971949509116%\n",
      "Fold 7: Accuracy = 47.0472717071118%\n",
      "Fold 8: Accuracy = 46.037312386028894%\n",
      "Fold 9: Accuracy = 45.79884976855099%\n",
      "Average Accuracy = 45.72525114219836%\n",
      "\n",
      "Accuracy on Test Data: 0.46189765054792503\n",
      "f1_score on Test Data: 0.4129455306273603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# do now Knn with k = 29 and applie 10 cross fold\n",
    "\n",
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier(n_neighbors=29)\n",
    "\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn optimized:\")\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(knn_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "print()\n",
    "print(\"Accuracy on Test Data: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"f1_score on Test Data: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.5175914629871131 with params {'criterion': 'gini', 'max_depth': 10, 'max_features': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "#Tuning of algorithm\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'max_depth':[3,5,10,None],\n",
    "     'criterion':[\"gini\", \"entropy\"],\n",
    "     'max_features':[\"auto\",\"log2\",None]\n",
    "}\n",
    "\n",
    "\n",
    "# create the grid search instance\n",
    "grid_search_estimator = GridSearchCV(rf_reg, parameters, scoring='accuracy', cv=stratified_10_fold_cv, return_train_score=False)\n",
    "\n",
    "# run the grid search\n",
    "grid_search_estimator.fit(features_train, rating_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "#display(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Random Forrest optimized:\n",
      "Fold 0: Accuracy = 51.66806840482197%\n",
      "Fold 1: Accuracy = 51.41575553686572%\n",
      "Fold 2: Accuracy = 51.32482826300294%\n",
      "Fold 3: Accuracy = 51.33884760970139%\n",
      "Fold 4: Accuracy = 52.1312394840157%\n",
      "Fold 5: Accuracy = 53.2258064516129%\n",
      "Fold 6: Accuracy = 51.99158485273492%\n",
      "Fold 7: Accuracy = 51.73236077991304%\n",
      "Fold 8: Accuracy = 51.35362603450694%\n",
      "Fold 9: Accuracy = 51.38168046009258%\n",
      "Average Accuracy = 51.7563797877268%\n",
      "\n",
      "Accuracy on Test Data: 0.5174894306207013\n",
      "f1_score on Test Data: 0.4669620780886967\n"
     ]
    }
   ],
   "source": [
    "# do now Random Forest with entropy, maxdeepth 3 and applie 10 cross fold\n",
    "\n",
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier(criterion='gini', max_depth=10, max_features=None)\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores Random Forrest optimized:\")\n",
    "\n",
    "\n",
    "#compute accuracy score\n",
    "\n",
    "accuracy_knn = cross_val_score(rf_reg, features_train, rating_train, cv=stratified_10_fold_cv, scoring='accuracy')\n",
    "\n",
    "for i, acc in enumerate(accuracy_knn):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc * 100.0))\n",
    "\n",
    "print(\"Average Accuracy = {}%\".format(accuracy_knn.mean() * 100.0))\n",
    "print()\n",
    "print(\"Accuracy on Test Data: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"f1_score on Test Data: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
