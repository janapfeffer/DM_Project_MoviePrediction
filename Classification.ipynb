{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from math import sqrt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after import: 7517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>id</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>History</th>\n",
       "      <th>Western</th>\n",
       "      <th>Music</th>\n",
       "      <th>Family</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>orig_ml</th>\n",
       "      <th>orig_es</th>\n",
       "      <th>orig_bn</th>\n",
       "      <th>orig_ab</th>\n",
       "      <th>orig_wo</th>\n",
       "      <th>orig_ca</th>\n",
       "      <th>orig_ru</th>\n",
       "      <th>orig_id</th>\n",
       "      <th>orig_is</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000000</td>\n",
       "      <td>862</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000000</td>\n",
       "      <td>8844</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000000</td>\n",
       "      <td>949</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58000000</td>\n",
       "      <td>710</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98000000</td>\n",
       "      <td>1408</td>\n",
       "      <td>119.0</td>\n",
       "      <td>137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget    id  runtime  vote_count  History  Western  Music  Family  \\\n",
       "0  30000000   862     81.0        5415      0.0      0.0    0.0     1.0   \n",
       "1  65000000  8844    104.0        2413      0.0      0.0    0.0     1.0   \n",
       "2  60000000   949    170.0        1886      0.0      0.0    0.0     0.0   \n",
       "3  58000000   710    130.0        1194      0.0      0.0    0.0     0.0   \n",
       "4  98000000  1408    119.0         137      0.0      0.0    0.0     0.0   \n",
       "\n",
       "   Comedy  Drama  ...  orig_ml  orig_es  orig_bn  orig_ab  orig_wo  orig_ca  \\\n",
       "0     1.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0    1.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4     0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   orig_ru  orig_id  orig_is  director  \n",
       "0      0.0      0.0      0.0      1709  \n",
       "1      0.0      0.0      0.0      1645  \n",
       "2      0.0      0.0      0.0      2338  \n",
       "3      0.0      0.0      0.0      2231  \n",
       "4      0.0      0.0      0.0      2812  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "df_movies = pd.read_csv(\"regressionPreprocessing.csv\")\n",
    "print(\"Length after import: \" + str(len(df_movies)))\n",
    "df_movies = df_movies.fillna(0)\n",
    "df_movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     budget  History  Western  Music  Family  Comedy  Drama  Foreign  Action  \\\n",
      "0  30000000      0.0      0.0    0.0     1.0     1.0    0.0      0.0     0.0   \n",
      "1  65000000      0.0      0.0    0.0     1.0     0.0    0.0      0.0     0.0   \n",
      "2  60000000      0.0      0.0    0.0     0.0     0.0    1.0      0.0     1.0   \n",
      "3  58000000      0.0      0.0    0.0     0.0     0.0    0.0      0.0     1.0   \n",
      "4  98000000      0.0      0.0    0.0     0.0     0.0    0.0      0.0     1.0   \n",
      "\n",
      "   Horror  ...  Documentary  Thriller  TV Movie  Crime  Science Fiction  \\\n",
      "0     0.0  ...          0.0       0.0       0.0    0.0              0.0   \n",
      "1     0.0  ...          0.0       0.0       0.0    0.0              0.0   \n",
      "2     0.0  ...          0.0       1.0       0.0    1.0              0.0   \n",
      "3     0.0  ...          0.0       1.0       0.0    0.0              0.0   \n",
      "4     0.0  ...          0.0       0.0       0.0    0.0              0.0   \n",
      "\n",
      "   Fantasy  War  Adventure    rating  director  \n",
      "0      0.0  0.0        0.0  3.598930      1709  \n",
      "1      1.0  0.0        1.0  3.760163      1645  \n",
      "2      0.0  0.0        0.0  3.905544      2338  \n",
      "3      0.0  0.0        1.0  2.740334      2231  \n",
      "4      0.0  0.0        1.0  3.710181      2812  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'History', 'Western', 'Music', 'Family', 'Comedy', 'Drama',\n",
       "       'Foreign', 'Action', 'Horror', 'Mystery', 'Romance', 'Animation',\n",
       "       'Documentary', 'Thriller', 'TV Movie', 'Crime', 'Science Fiction',\n",
       "       'Fantasy', 'War', 'Adventure', 'rating', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns that are not needed\n",
    "features_to_remove = ['vote_count','+18','id','actors','spokenLanguages','productionCountries','productionCompanies','original_language','hasHomepage','part_of_collection''orig_lv', 'orig_el', 'orig_fa', 'orig_tl', 'orig_ta', 'orig_th',\n",
    "       'orig_mn', 'orig_zh', 'orig_te', 'orig_kk', 'orig_zu', 'orig_et',\n",
    "       'orig_mr', 'orig_eu', 'orig_sv', 'orig_no', 'orig_pl', 'orig_cs',\n",
    "       'orig_cy', 'orig_bs', 'orig_de', 'orig_lo', 'orig_xx', 'orig_ko',\n",
    "       'orig_hu', 'orig_sr', 'orig_da', 'orig_pt', 'orig_nl', 'orig_en',\n",
    "       'orig_it', 'orig_tr', 'orig_hr', 'orig_cn', 'orig_ka', 'orig_ar',\n",
    "       'orig_ja', 'orig_0', 'orig_hi', 'orig_ro', 'orig_af', 'orig_sk',\n",
    "       'orig_fr', 'orig_fi', 'orig_he', 'orig_uk', 'orig_bg', 'orig_ml',\n",
    "       'orig_es', 'orig_bn', 'orig_ab', 'orig_wo', 'orig_ca', 'orig_ru',\n",
    "       'orig_id', 'orig_is', 'orig_lv',\n",
    "        'runtime',\n",
    "       'part_of_collection', '18+']\n",
    "for i in features_to_remove:\n",
    "    if i in df_movies.columns:\n",
    "        df_movies = df_movies.drop(columns=i)\n",
    "print(df_movies.head(5))\n",
    "df_movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4510 Features and 4510 Ratings\n",
      "Test: 3007 Features and 3007 Ratings\n"
     ]
    }
   ],
   "source": [
    "# separate features and target variable\n",
    "rating = df_movies['rating'] # weight\n",
    "features = df_movies.drop(columns=['rating'])\n",
    "\n",
    "# encode labels\n",
    "lab_enc = LabelEncoder()\n",
    "rating = lab_enc.fit_transform(rating)\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(\n",
    "    features, rating, test_size=0.4, random_state=42)\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy: 0.035583638177585634\n",
      "Precision: 0.0024860149416241054\n",
      "Recall: 0.035583638177585634\n",
      "f1_score: 0.0045887389910926404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# create and fit a knn classifier\n",
    "knn_reg = KNeighborsClassifier(n_neighbors=1000)\n",
    "knn_reg.fit(features_train, rating_train)\n",
    "rating_pred_knn = knn_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "#compute the confusion matrix\n",
    "cnf_matrix = confusion_matrix(rating_test, rating_pred_knn)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_knn)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_knn, average='weighted')))\n",
    "\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy: 0.008313934153641503\n",
      "Precision: 0.007210381211635159\n",
      "Recall: 0.008313934153641503\n",
      "f1_score: 0.007235894096123855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a RandomForestClassifier\n",
    "rf_reg = RandomForestClassifier()\n",
    "rf_reg.fit(features_train, rating_train)\n",
    "rating_pred_rf = rf_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "#compute the confusion matrix\n",
    "cnf_matrix = confusion_matrix(rating_test, rating_pred_rf)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_rf)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_rf, average='weighted')))\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy: 0.008979048885932824\n",
      "Precision: 0.007415882136468402\n",
      "Recall: 0.008979048885932824\n",
      "f1_score: 0.007582853072449445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a DecisionTreeClassifier\n",
    "dt_reg = DecisionTreeClassifier()\n",
    "dt_reg.fit(features_train, rating_train)\n",
    "rating_pred_dt = dt_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "#compute the confusion matrix\n",
    "cnf_matrix = confusion_matrix(rating_test, rating_pred_dt)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_dt)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_dt, average='weighted')))\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n",
    "#from sklearn import tree\n",
    "#tree.plot_tree(dt_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "[[6 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [8 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "Accuracy: 0.0029930162953109413\n",
      "Precision: 0.005010749114532075\n",
      "Recall: 0.0029930162953109413\n",
      "f1_score: 0.0016524254020128335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a GaussianNB\n",
    "nb_reg = GaussianNB()\n",
    "nb_reg.fit(features_train, rating_train)\n",
    "rating_pred_nb = nb_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "#compute the confusion matrix\n",
    "cnf_matrix = confusion_matrix(rating_test, rating_pred_nb)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_nb)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_nb, average='weighted')))\n",
    "\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores knn:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy: 0.03392085134685733\n",
      "Precision: 0.005814761747761968\n",
      "Recall: 0.03392085134685733\n",
      "f1_score: 0.0067314507175342524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\d060445\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##### create and fit a SVC\n",
    "svc_reg = SVC()\n",
    "svc_reg.fit(features_train, rating_train)\n",
    "rating_pred_svc = svc_reg.predict(features_test)\n",
    "\n",
    "print(\"Scores knn:\")\n",
    "#compute the confusion matrix\n",
    "cnf_matrix = confusion_matrix(rating_test, rating_pred_svc)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#compute accuracy score\n",
    "print(\"Accuracy: {}\".format(accuracy_score(rating_test, rating_pred_svc)))\n",
    "print(\"Precision: {}\".format(precision_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"Recall: {}\".format(recall_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "print(\"f1_score: {}\".format(f1_score(rating_test, rating_pred_svc, average='weighted')))\n",
    "\n",
    "#plot the confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=lab_enc.classes_, title='KNN Classifier')\n",
    "\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
