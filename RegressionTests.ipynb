{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after import: 43872\n",
      "Features after import: 130\n"
     ]
    }
   ],
   "source": [
    "#df_joined = pd.read_csv(\"regressionPreprocessing_short.csv\")\n",
    "df_joined = pd.read_csv(\"regressionPreprocessing.csv\")\n",
    "df_joined = df_joined.fillna(0)\n",
    "print(\"Length after import: \" + str(len(df_joined)))\n",
    "print(\"Features after import: \" + str(len(df_joined.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neue Reihenfolge\n",
    "#cols = df_joined.columns.tolist()\n",
    "#cols = cols[-1:] + cols[:-1] # letzte kommt an erster Stelle\n",
    "#df_joined = df_joined[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meaning out 0 budgets - there are a lot, so this is better than removing the rows\n",
    "df_joined['budget']=df_joined['budget'].replace(0,df_joined['budget'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Features, which are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>History</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Family</th>\n",
       "      <th>Music</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Bette Davis</th>\n",
       "      <th>John Carradine</th>\n",
       "      <th>Lionel Barrymore</th>\n",
       "      <th>Charles Lane</th>\n",
       "      <th>John Wayne</th>\n",
       "      <th>Henry Fonda</th>\n",
       "      <th>Michael Caine</th>\n",
       "      <th>Boris Karloff</th>\n",
       "      <th>James Franco</th>\n",
       "      <th>Grey Griffin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.500000e+07</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.328343e+06</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.600000e+07</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.328343e+06</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget  runtime  Mystery  Foreign  History  TV Movie  Crime  Family  \\\n",
       "0  3.000000e+07     81.0      0.0      0.0      0.0       0.0    0.0     1.0   \n",
       "1  6.500000e+07    104.0      0.0      0.0      0.0       0.0    0.0     1.0   \n",
       "2  4.328343e+06    101.0      0.0      0.0      0.0       0.0    0.0     0.0   \n",
       "3  1.600000e+07    127.0      0.0      0.0      0.0       0.0    0.0     0.0   \n",
       "4  4.328343e+06    106.0      0.0      0.0      0.0       0.0    0.0     0.0   \n",
       "\n",
       "   Music  Documentary  ...  Bette Davis  John Carradine  Lionel Barrymore  \\\n",
       "0    0.0          0.0  ...            0               0                 0   \n",
       "1    0.0          0.0  ...            0               0                 0   \n",
       "2    0.0          0.0  ...            0               0                 0   \n",
       "3    0.0          0.0  ...            0               0                 0   \n",
       "4    0.0          0.0  ...            0               0                 0   \n",
       "\n",
       "   Charles Lane  John Wayne  Henry Fonda  Michael Caine  Boris Karloff  \\\n",
       "0             0           0            0              0              0   \n",
       "1             0           0            0              0              0   \n",
       "2             0           0            0              0              0   \n",
       "3             0           0            0              0              0   \n",
       "4             0           0            0              0              0   \n",
       "\n",
       "   James Franco  Grey Griffin  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_remove = ['director','+18','18+','actors','productionCompanies','productionCountries','imdbId','spokenLanguages','budget_norm','runtime_norm']\n",
    "for i in features_to_remove:\n",
    "    if i in df_joined.columns:\n",
    "        df_joined = df_joined.drop(columns=i)\n",
    "df_joined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "#### features_train + rating_train ;                   features_test + rating_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 39484 Features and 39484 Ratings\n",
      "Test: 4388 Features and 4388 Ratings\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate features and target variable\n",
    "rating = df_joined['rating'] # weight\n",
    "features = df_joined.drop(columns=['rating'])\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(\n",
    "    features, rating, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('budget', 0.00972647)\n",
      "('runtime', 0.009352073)\n",
      "('Mystery', 0.020576613)\n",
      "('Foreign', 0.00800058)\n",
      "('History', 0.021636745)\n",
      "('TV Movie', 0.010740736)\n",
      "('Crime', 0.017331397)\n",
      "('Family', 0.0121769775)\n",
      "('Music', 0.027358606)\n",
      "('Documentary', 0.15778288)\n",
      "('Action', 0.027183298)\n",
      "('Fantasy', 0.0143706715)\n",
      "('War', 0.008272914)\n",
      "('Animation', 0.019134324)\n",
      "('Thriller', 0.030215187)\n",
      "('Science Fiction', 0.039088923)\n",
      "('Drama', 0.12015697)\n",
      "('Adventure', 0.009992758)\n",
      "('Romance', 0.012119901)\n",
      "('Horror', 0.39320117)\n",
      "('Comedy', 0.011054753)\n",
      "('Western', 0.0057188934)\n",
      "('part_of_collection', 0.00679045)\n",
      "('hasHomepage', 0.008016672)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressor = XGBRegressor(colsample_bytree= 0.6, gamma= 0.7, max_depth= 4, min_child_weight= 5,\n",
    "                         subsample = 0.8, objective='reg:squarederror')\n",
    "regressor.fit(features_train, rating_train)\n",
    "\n",
    "importances = {}\n",
    "\n",
    "count = 0\n",
    "for feature_importance in regressor.feature_importances_:\n",
    "    if feature_importance > 0.002:\n",
    "        feature_name = features_train.columns[count]\n",
    "        importances[feature_name] = feature_importance\n",
    "    count+=1\n",
    "\n",
    "for a in importances.items():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features which are not important enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  24\n",
      "Train: 39484 Features and 39484 Ratings\n",
      "Test: 4388 Features and 4388 Ratings\n"
     ]
    }
   ],
   "source": [
    "rating = df_joined['rating']\n",
    "\n",
    "for i in df_joined.columns:\n",
    "    if i not in importances:\n",
    "        df_joined = df_joined.drop(columns=i)\n",
    "\n",
    "print(\"Features: \", len(df_joined.columns))\n",
    "df_joined.head(5)\n",
    "\n",
    "features = df_joined\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(\n",
    "    features, rating, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.931156899673925\n",
      "[ 7.81635983e-10  3.29050663e-04  9.61352717e-02 -3.67269799e-02\n",
      "  1.41236519e-01  5.45261807e-02  3.19881227e-02 -9.69628173e-02\n",
      "  7.45756217e-02  4.16282607e-01 -1.11968879e-01  6.64118934e-02\n",
      "  5.80847780e-02  1.74059401e-01 -3.31924503e-02 -1.26737171e-01\n",
      "  2.23198899e-01 -9.41053905e-03  1.91587787e-02 -4.15132345e-01\n",
      "  3.34635197e-02  4.25870242e-02 -3.65027167e-03 -2.03660929e-02]\n",
      "[('budget', 7.816359831492934e-10), ('runtime', 0.00032905066317639987), ('Mystery', 0.0961352716614105), ('Foreign', -0.03672697991095928), ('History', 0.14123651866207088), ('TV Movie', 0.05452618071029435), ('Crime', 0.031988122743234766), ('Family', -0.09696281732620733), ('Music', 0.07457562174999581), ('Documentary', 0.41628260668811634), ('Action', -0.11196887919313202), ('Fantasy', 0.06641189336532126), ('War', 0.05808477798941179), ('Animation', 0.17405940131822234), ('Thriller', -0.03319245031518115), ('Science Fiction', -0.126737170687742), ('Drama', 0.22319889907487012), ('Adventure', -0.009410539045569497), ('Romance', 0.01915877873406856), ('Horror', -0.41513234515853564), ('Comedy', 0.03346351971529926), ('Western', 0.042587024155813745), ('part_of_collection', -0.003650271674817385), ('hasHomepage', -0.02036609293159594)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(features_train, rating_train)\n",
    "\n",
    "# print the coefficients\n",
    "print(lm2.intercept_)\n",
    "print(lm2.coef_)\n",
    "\n",
    "print(list(zip(features_train.columns, lm2.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.5110551070770686\n",
      "MSE:  0.4815075136463717\n",
      "RMSE 0.6939074244064346\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(features_train,rating_train)\n",
    "y_pred = lm2.predict(features_test)\n",
    "\n",
    "# calculate MAE, MSE, RMSE\n",
    "print(\"MAE: \", metrics.mean_absolute_error(rating_test, y_pred))\n",
    "print(\"MSE: \", metrics.mean_squared_error(rating_test, y_pred))\n",
    "print(\"RMSE\", np.sqrt(metrics.mean_squared_error(rating_test, y_pred)))\n",
    "\n",
    "# MSE is more popular than MAE because MSE \"punishes\" larger errors. But, RMSE is even more popular than MSE because RMSE is interpretable in the \"y\" units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Dimensions with PCA (data visualization)\n",
    "#### principalDf contains the features in only 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separating out the features\n",
    "# x = features\n",
    "# y = rating\n",
    "\n",
    "# # Standardize the Data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)# X dimensions to 2\n",
    "# principalComponents = pca.fit_transform(x)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "# finalDf = pd.concat([principalDf, df_joined[['rating']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 39484 Features and 39484 Ratings\n",
      "Test: 4388 Features and 4388 Ratings\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only\n",
    "scaler.fit(features_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_features = scaler.transform(features_train)\n",
    "test_features = scaler.transform(features_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "\n",
    "pca.fit(train_features)\n",
    "\n",
    "train_features = pca.transform(train_features)\n",
    "test_features = pca.transform(test_features)\n",
    "\n",
    "print(\"Train: \" + str(len(train_features)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(test_features)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8c7a7538cc7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrating_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(features_train,rating_train)\n",
    "\n",
    "#print(reg.coef_)       # coefficients w\n",
    "print(reg.intercept_)\n",
    "\n",
    "print(\"#################\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(features_train, rating_train)\n",
    "\n",
    "rr = Ridge(alpha=0.01) # higher the alpha value, more restriction on the coefficients; low alpha > more generalization, coefficients are barely\n",
    "# restricted and in this case linear and ridge regression resembles\n",
    "rr.fit(features_train, rating_train)\n",
    "\n",
    "rr100 = Ridge(alpha=100) #  comparison with alpha value\n",
    "rr100.fit(features_train, rating_train)\n",
    "\n",
    "train_score=lr.score(features_train, rating_train)\n",
    "test_score=lr.score(features_test, rating_test)\n",
    "\n",
    "Ridge_train_score = rr.score(features_train,rating_train)\n",
    "Ridge_test_score = rr.score(features_test, rating_test)\n",
    "\n",
    "Ridge_train_score100 = rr100.score(features_train,rating_train)\n",
    "Ridge_test_score100 = rr100.score(features_test, rating_test)\n",
    "\n",
    "print(\"linear regression train score:\", train_score)\n",
    "print(\"linear regression test score:\", test_score)\n",
    "print(\"ridge regression train score low alpha:\", Ridge_train_score)\n",
    "print(\"ridge regression test score low alpha:\", Ridge_test_score)\n",
    "print(\"ridge regression train score high alpha:\", Ridge_train_score100)\n",
    "print(\"ridge regression test score high alpha:\", Ridge_test_score100)\n",
    "\n",
    "plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 0.01$',zorder=7) # zorder for ordering the markersplt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; $\\alpha = 100$') # alpha here is for transparencyplt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "print(\"### Lasso Standard (Alpha=1) ###\")\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(features_train,rating_train)\n",
    "train_score=lasso.score(features_train,rating_train)\n",
    "test_score=lasso.score(features_test,rating_test)\n",
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "\n",
    "print(\"training score: \", train_score )\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "print(\"\\n### Lasso (low Alpha = 0.01) ###\")\n",
    "\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lasso001.fit(features_train,rating_train)\n",
    "train_score001=lasso001.score(features_train,rating_train)\n",
    "test_score001=lasso001.score(features_test,rating_test)\n",
    "coeff_used001 = np.sum(lasso001.coef_!=0)\n",
    "\n",
    "print(\"training score for alpha=0.01:\", train_score001)\n",
    "print(\"test score for alpha =0.01: \", test_score001)\n",
    "print(\"number of features used: for alpha =0.01:\", coeff_used001)\n",
    "\n",
    "print(\"\\n### Lasso (very low Alpha = 0.0001) ###\")\n",
    "\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n",
    "lasso00001.fit(features_train,rating_train)\n",
    "train_score00001=lasso00001.score(features_train,rating_train)\n",
    "test_score00001=lasso00001.score(features_test,rating_test)\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "\n",
    "print(\"training score for alpha=0.0001:\", train_score00001)\n",
    "print(\"test score for alpha =0.0001: \", test_score00001)\n",
    "print(\"number of features used: for alpha =0.0001:\", coeff_used00001)\n",
    "\n",
    "print(\"\\n### Linear Regression ###\")\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(features_train,rating_train)\n",
    "lr_train_score=lr.score(features_train,rating_train)\n",
    "lr_test_score=lr.score(features_test,rating_test)\n",
    "\n",
    "print(\"LR training score:\", lr_train_score)\n",
    "print(\"LR test score: \", lr_test_score)\n",
    "\n",
    "print(\"\\n### Visualisierung ###\")\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; $\\alpha = 1$',zorder=7) # alpha here is for transparency\n",
    "plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; $\\alpha = 0.01$') # alpha here is for transparency\n",
    "\n",
    "plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Lasso; $\\alpha = 1$',zorder=7) # alpha here is for transparency\n",
    "plt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Lasso; $\\alpha = 0.01$') # alpha here is for transparency\n",
    "plt.plot(lasso00001.coef_,alpha=0.8,linestyle='none',marker='v',markersize=6,color='black',label=r'Lasso; $\\alpha = 0.00001$') # alpha here is for transparency\n",
    "plt.plot(lr.coef_,alpha=0.7,linestyle='none',marker='o',markersize=5,color='green',label='Linear Regression',zorder=2)\n",
    "\n",
    "plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "print(\"### Bayesian Ridge Regression ###\")\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(features_train,rating_train)\n",
    "train_score=reg.score(features_train,rating_train)\n",
    "test_score=reg.score(features_test,rating_test)\n",
    "#coeff_used = np.sum(reg.coef_!=0)\n",
    "\n",
    "print(\"training score: \", train_score )\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate features and target variable\n",
    "rating = df_joined['rating'] # weight\n",
    "features = df_joined.drop(columns=['rating'])\n",
    "\n",
    "# create a train/test split\n",
    "features_train, features_test, rating_train, rating_test = train_test_split(\n",
    "    features, rating, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Train: \" + str(len(features_train)) + \" Features and \" + str(len(rating_train)) + \" Ratings\")\n",
    "print(\"Test: \" + str(len(features_test)) + \" Features and \" + str(len(rating_test)) + \" Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### MLP Regressor (multilayer neuronal network) ###\")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(hidden_layer_sizes=(15,),\n",
    "            activation='relu', # 'logistic' / 'relu'\n",
    "            solver='sgd', # 'sgd'/'adam'\n",
    "            learning_rate='adaptive', # default â€˜constantâ€™\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=0.01,\n",
    "            alpha=0.0001) # default 0.0001\n",
    "reg.fit(features_train,rating_train)\n",
    "train_score=reg.score(features_train,rating_train)\n",
    "test_score=reg.score(features_test,rating_test)\n",
    "#coeff_used = np.sum(reg.coefs_!=0)\n",
    "\n",
    "print(\"training score: \", train_score )\n",
    "print(\"test score: \", test_score)\n",
    "print(\"loss: \", reg.loss_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
